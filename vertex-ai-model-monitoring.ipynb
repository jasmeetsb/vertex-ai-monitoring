{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Blog Post - Vertex AI Model monitoring capabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.json_format import MessageToJson, ParseDict\n",
    "from google.protobuf.struct_pb2 import Struct, Value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference:*\n",
    "\n",
    "Training code source : [Link](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/community/gapic/automl/showcase_automl_tabular_binary_classification_batch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! pip3 install -U google-cloud-aiplatform $USER_FLAG\n",
    "#! pip3 install -U google-cloud-storage $USER_FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Restart the Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCP Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\" \n",
    "PROJECT_ID = \"vertex-ai-blog\"  #Replace with your GCP Project\n",
    "print(\"Project ID:\", PROJECT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOY_GPU, DEPLOY_NGPU = (aip.AcceleratorType.NVIDIA_TESLA_K80, 1)\n",
    "MACHINE_TYPE = \"n1-standard\"\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API service endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "# Vertex location root path for your dataset, model and endpoint resources\n",
    "PARENT = \"projects/\" + PROJECT_ID + \"/locations/\" + REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GCS Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://vertex-ai-blog\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test access to the bucket\n",
    "!gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client options - same for all services\n",
    "client_options = {\"api_endpoint\": API_ENDPOINT}\n",
    "\n",
    "# Create client instances for key tasks to be performed\n",
    "def create_dataset_client():\n",
    "    client = aip.DatasetServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_model_client():\n",
    "    client = aip.ModelServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "def create_pipeline_client():\n",
    "    client = aip.PipelineServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "# Needed for batch prediction\n",
    "def create_job_client():\n",
    "    client = aip.JobServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "# Endpoint creation\n",
    "def create_endpoint_client():\n",
    "    client = aip.EndpointServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "# Needed for Prediction call\n",
    "def create_prediction_client():\n",
    "    client = aip.PredictionServiceClient(client_options=client_options)\n",
    "    return client\n",
    "\n",
    "\n",
    "clients = {}\n",
    "clients[\"dataset\"] = create_dataset_client()\n",
    "clients[\"model\"] = create_model_client()\n",
    "clients[\"pipeline\"] = create_pipeline_client()\n",
    "clients[\"job\"] = create_job_client()\n",
    "clients[\"endpoint\"] = create_endpoint_client()\n",
    "clients[\"prediction\"] = create_prediction_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank marketing Dataset\n",
    "# Dataset Source: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict \n",
    "# the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "IMPORT_FILE = \"gs://cloud-ml-tables-data/bank-marketing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternate way of creating dataset in Vertex\n",
    "from typing import List, Union\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "def create_and_import_dataset_tabular_gcs_sample(\n",
    "    display_name: str, project: str, location: str, gcs_source: Union[str, List[str]],):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    dataset = aiplatform.TabularDataset.create(\n",
    "        display_name=display_name, gcs_source=gcs_source,)\n",
    "\n",
    "    dataset.wait()\n",
    "\n",
    "    print(f'\\tDataset: \"{dataset.display_name}\"')\n",
    "    print(f'\\tname: \"{dataset.resource_name}\"')\n",
    "    \n",
    "    return(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = create_and_import_dataset_tabular_gcs_sample(\"bank-\" + TIMESTAMP, PROJECT_ID, REGION, IMPORT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(pipeline_name, model_name, dataset, schema, task):\n",
    "\n",
    "    dataset_id = dataset.split(\"/\")[-1]\n",
    "\n",
    "    input_config = {\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"fraction_split\": {\n",
    "            \"training_fraction\": 0.8,\n",
    "            \"validation_fraction\": 0.1,\n",
    "            \"test_fraction\": 0.1,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    training_pipeline = {\n",
    "        \"display_name\": pipeline_name,\n",
    "        \"training_task_definition\": schema,\n",
    "        \"training_task_inputs\": task,\n",
    "        \"input_data_config\": input_config,\n",
    "        \"model_to_upload\": {\"display_name\": model_name},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        pipeline = clients[\"pipeline\"].create_training_pipeline(\n",
    "            parent=PARENT, training_pipeline=training_pipeline\n",
    "        )\n",
    "        print(pipeline)\n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)\n",
    "        return None\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'Deposit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "task_transformations:automl,tabular,bank"
   },
   "outputs": [],
   "source": [
    "TRANSFORMATIONS = [\n",
    "    {\"auto\": {\"column_name\": \"Age\"}},\n",
    "    {\"auto\": {\"column_name\": \"Job\"}},\n",
    "    {\"auto\": {\"column_name\": \"MaritalStatus\"}},\n",
    "    {\"auto\": {\"column_name\": \"Education\"}},\n",
    "    {\"auto\": {\"column_name\": \"Default\"}},\n",
    "    {\"auto\": {\"column_name\": \"Balance\"}},\n",
    "    {\"auto\": {\"column_name\": \"Housing\"}},\n",
    "    {\"auto\": {\"column_name\": \"Loan\"}},\n",
    "    {\"auto\": {\"column_name\": \"Contact\"}},\n",
    "    {\"auto\": {\"column_name\": \"Day\"}},\n",
    "    {\"auto\": {\"column_name\": \"Month\"}},\n",
    "    {\"auto\": {\"column_name\": \"Duration\"}},\n",
    "    {\"auto\": {\"column_name\": \"Campaign\"}},\n",
    "    {\"auto\": {\"column_name\": \"PDays\"}},\n",
    "    {\"auto\": {\"column_name\": \"POutcome\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "task_requirements:automl,tabular,transformations"
   },
   "outputs": [],
   "source": [
    "PIPE_NAME = \"bank_pipe-\" + TIMESTAMP\n",
    "MODEL_NAME = \"bank_model-\" + TIMESTAMP\n",
    "\n",
    "TRAINING_SCHEMA = \"gs://google-cloud-aiplatform/schema/trainingjob/definition/automl_tables_1.0.0.yaml\"\n",
    "\n",
    "task = Value(\n",
    "    struct_value=Struct(\n",
    "        fields={\n",
    "            \"target_column\": Value(string_value=label_column),\n",
    "            \"prediction_type\": Value(string_value=\"classification\"),\n",
    "            \"train_budget_milli_node_hours\": Value(number_value=1000),\n",
    "            \"disable_early_stopping\": Value(bool_value=False),\n",
    "            \"transformations\": json_format.ParseDict(TRANSFORMATIONS, Value()),\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "response = create_pipeline(PIPE_NAME, MODEL_NAME, dataset_id, TRAINING_SCHEMA, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline_id:response"
   },
   "source": [
    "Now save the unique identifier of the training pipeline you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline_id:response"
   },
   "outputs": [],
   "source": [
    "# The full unique ID for the pipeline\n",
    "pipeline_id = response.name\n",
    "# The short numeric ID for the pipeline\n",
    "pipeline_short_id = pipeline_id.split(\"/\")[-1]\n",
    "\n",
    "print(pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_pipeline(name, silent=False):\n",
    "    response = clients[\"pipeline\"].get_training_pipeline(name=name)\n",
    "    if silent:\n",
    "        return response\n",
    "\n",
    "    print(\"pipeline\")\n",
    "    print(\" name:\", response.name)\n",
    "    print(\" display_name:\", response.display_name)\n",
    "    print(\" state:\", response.state)\n",
    "    print(\" training_task_definition:\", response.training_task_definition)\n",
    "    print(\" training_task_inputs:\", dict(response.training_task_inputs))\n",
    "    print(\" create_time:\", response.create_time)\n",
    "    print(\" start_time:\", response.start_time)\n",
    "    print(\" end_time:\", response.end_time)\n",
    "    print(\" update_time:\", response.update_time)\n",
    "    print(\" labels:\", dict(response.labels))\n",
    "    return response\n",
    "\n",
    "\n",
    "response = get_training_pipeline(pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitor when the training job would be completed\n",
    "while True:\n",
    "    response = get_training_pipeline(pipeline_id, True)\n",
    "    if response.state != aip.PipelineState.PIPELINE_STATE_SUCCEEDED:\n",
    "        print(\"Training job has not completed:\", response.state)\n",
    "        model_to_deploy_id = None\n",
    "        if response.state == aip.PipelineState.PIPELINE_STATE_FAILED:\n",
    "            raise Exception(\"Training Job Failed\")\n",
    "    else:\n",
    "        model_to_deploy = response.model_to_upload\n",
    "        model_to_deploy_id = model_to_deploy.name\n",
    "        print(\"Training Time:\", response.end_time - response.start_time)\n",
    "        break\n",
    "    time.sleep(60)\n",
    "\n",
    "print(\"model to deploy:\", model_to_deploy_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_model_evaluations(name):\n",
    "    response = clients[\"model\"].list_model_evaluations(parent=name)\n",
    "    for evaluation in response:\n",
    "        print(\"model_evaluation\")\n",
    "        print(\" name:\", evaluation.name)\n",
    "        print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "        metrics = json_format.MessageToDict(evaluation._pb.metrics)\n",
    "        for metric in metrics.keys():\n",
    "            print(metric)\n",
    "        print(\"logloss\", metrics[\"logLoss\"])\n",
    "        print(\"auPrc\", metrics[\"auPrc\"])\n",
    "\n",
    "    return evaluation.name\n",
    "\n",
    "last_evaluation = list_model_evaluations(model_to_deploy_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Testing - Delete\n",
    "#model_to_deploy_id = \"projects/92852031310/locations/us-central1/models/4681676530605096960\"\n",
    "model_to_deploy_id = \"projects/92852031310/locations/us-central1/models/2880518154633609216\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model for online predictions and monitoring demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NODES = 1\n",
    "MAX_NODES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = \"bank_endpoint-\" + TIMESTAMP\n",
    "\n",
    "\n",
    "def create_endpoint(display_name):\n",
    "    endpoint = {\"display_name\": display_name}\n",
    "    response = clients[\"endpoint\"].create_endpoint(parent=PARENT, endpoint=endpoint)\n",
    "    print(\"Long running operation:\", response.operation.name)\n",
    "\n",
    "    result = response.result(timeout=300)\n",
    "    print(\"result\")\n",
    "    print(\" name:\", result.name)\n",
    "    print(\" display_name:\", result.display_name)\n",
    "    print(\" description:\", result.description)\n",
    "    print(\" labels:\", result.labels)\n",
    "    print(\" create_time:\", result.create_time)\n",
    "    print(\" update_time:\", result.update_time)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = create_endpoint(ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full unique ID for the endpoint\n",
    "endpoint_id = result.name\n",
    "# The short numeric ID for the endpoint\n",
    "endpoint_short_id = endpoint_id.split(\"/\")[-1]\n",
    "\n",
    "print(endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_NAME = \"bank_deployed-\" + TIMESTAMP\n",
    "\n",
    "\n",
    "def deploy_model(\n",
    "    model, deployed_model_display_name, endpoint, traffic_split={\"0\": 100}\n",
    "):\n",
    "\n",
    "    if DEPLOY_GPU:\n",
    "        machine_spec = {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_type\": DEPLOY_GPU,\n",
    "            \"accelerator_count\": DEPLOY_NGPU,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\n",
    "            \"machine_type\": DEPLOY_COMPUTE,\n",
    "            \"accelerator_count\": 0,\n",
    "        }\n",
    "\n",
    "    deployed_model = {\n",
    "        \"model\": model,\n",
    "        \"display_name\": deployed_model_display_name,\n",
    "        \"dedicated_resources\": {\n",
    "            \"min_replica_count\": MIN_NODES,\n",
    "            \"max_replica_count\": MAX_NODES,\n",
    "            \"machine_spec\": machine_spec,\n",
    "        },\n",
    "        \"disable_container_logging\": False,\n",
    "    }\n",
    "\n",
    "    response = clients[\"endpoint\"].deploy_model(\n",
    "        endpoint=endpoint, deployed_model=deployed_model, traffic_split=traffic_split\n",
    "    )\n",
    "\n",
    "    print(\"Long running operation:\", response.operation.name)\n",
    "    result = response.result()\n",
    "    print(\"result\")\n",
    "    deployed_model = result.deployed_model\n",
    "    print(\" deployed_model\")\n",
    "    print(\"  id:\", deployed_model.id)\n",
    "    print(\"  model:\", deployed_model.model)\n",
    "    print(\"  display_name:\", deployed_model.display_name)\n",
    "    print(\"  create_time:\", deployed_model.create_time)\n",
    "\n",
    "    return deployed_model.id\n",
    "\n",
    "\n",
    "deployed_model_id = deploy_model(model_to_deploy_id, DEPLOYED_NAME, endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE = {\n",
    "    \"Age\": \"58\",\n",
    "    \"Job\": \"managment\",\n",
    "    \"MaritalStatus\": \"married\",\n",
    "    \"Education\": \"teritary\",\n",
    "    \"Default\": \"no\",\n",
    "    \"Balance\": \"2143\",\n",
    "    \"Housing\": \"yes\",\n",
    "    \"Loan\": \"no\",\n",
    "    \"Contact\": \"unknown\",\n",
    "    \"Day\": \"5\",\n",
    "    \"Month\": \"may\",\n",
    "    \"Duration\": \"261\",\n",
    "    \"Campaign\": \"1\",\n",
    "    \"PDays\": \"-1\",\n",
    "    \"Previous\": 0,\n",
    "    \"POutcome\": \"unknown\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction function\n",
    "def predict_item(data, endpoint, parameters_dict):\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    instances_list = [data]\n",
    "    instances = [json_format.ParseDict(s, Value()) for s in instances_list]\n",
    "\n",
    "    response = clients[\"prediction\"].predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    predictions = response.predictions\n",
    "    print(\"predictions\")\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test prediction\n",
    "predict_item(INSTANCE, endpoint_id, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add monitoring to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary.  Delete\n",
    "ENDPOINT = endpoint_id\n",
    "DEFAULT_INPUT = INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "print(ENDPOINT)\n",
    "print(\"request:\")\n",
    "pp.pprint(DEFAULT_INPUT)\n",
    "try:\n",
    "    #resp = send_predict_request(ENDPOINT, DEFAULT_INPUT)\n",
    "    resp = predict_item(INSTANCE, endpoint_id, None)\n",
    "    print(\"response\")\n",
    "    pp.pprint(resp)\n",
    "except Exception:\n",
    "    print(\"prediction request failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USER_EMAIL = \"jasmeetbhatia@google.com\"  # @param {type:\"string\"}\n",
    "JOB_NAME = \"bank_marketing_monitor\"\n",
    "\n",
    "# Sampling rate (optional, default=.8)\n",
    "LOG_SAMPLE_RATE = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "# Monitoring Interval in seconds (optional, default=3600).\n",
    "MONITOR_INTERVAL = 3600  # @param {type:\"number\"}\n",
    "\n",
    "\n",
    "# URI to training dataset.\n",
    "DATASET_GCS_URI = ['gs://cloud-ml-tables-data/bank-marketing.csv'] # @param {type:\"string\"}\n",
    "\n",
    "# Prediction target column name in training dataset.\n",
    "TARGET = \"Deposit\"\n",
    "\n",
    "# Skew and drift thresholds.\n",
    "SKEW_DEFAULT_THRESHOLDS = \"Age,Job,Balance,Education\"  # @param {type:\"string\"}\n",
    "SKEW_CUSTOM_THRESHOLDS = \"Balance:.5\"  # @param {type:\"string\"}\n",
    "DRIFT_DEFAULT_THRESHOLDS = \"Age,Job,Balance,Education\"  # @param {type:\"string\"}\n",
    "DRIFT_CUSTOM_THRESHOLDS = \"Balance:.5\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Monitoring Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monitoring_job(objective_configs):\n",
    "    # Create sampling configuration.\n",
    "    random_sampling = SamplingStrategy.RandomSampleConfig(sample_rate=LOG_SAMPLE_RATE)\n",
    "    sampling_config = SamplingStrategy(random_sample_config=random_sampling)\n",
    "\n",
    "    # Create schedule configuration.\n",
    "    duration = Duration(seconds=MONITOR_INTERVAL)\n",
    "    schedule_config = ModelDeploymentMonitoringScheduleConfig(monitor_interval=duration)\n",
    "\n",
    "    # Create alerting configuration.\n",
    "    emails = [USER_EMAIL]\n",
    "    email_config = ModelMonitoringAlertConfig.EmailAlertConfig(user_emails=emails)\n",
    "    alerting_config = ModelMonitoringAlertConfig(email_alert_config=email_config)\n",
    "\n",
    "    # Create the monitoring job.\n",
    "    #endpoint = f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "    endpoint = f\"{endpoint_id}\"\n",
    "    predict_schema = \"\"\n",
    "    analysis_schema = \"\"\n",
    "    job = ModelDeploymentMonitoringJob(\n",
    "        display_name=JOB_NAME,\n",
    "        endpoint=endpoint,\n",
    "        model_deployment_monitoring_objective_configs=objective_configs,\n",
    "        logging_sampling_strategy=sampling_config,\n",
    "        model_deployment_monitoring_schedule_config=schedule_config,\n",
    "        model_monitoring_alert_config=alerting_config,\n",
    "        predict_instance_schema_uri=predict_schema,\n",
    "        analysis_instance_schema_uri=analysis_schema,\n",
    "    )\n",
    "    options = dict(api_endpoint=API_ENDPOINT)\n",
    "    client = JobServiceClient(client_options=options)\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "    response = client.create_model_deployment_monitoring_job(\n",
    "        parent=parent, model_deployment_monitoring_job=job\n",
    "    )\n",
    "    print(\"Created monitoring job:\")\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_thresholds(default_thresholds, custom_thresholds):\n",
    "    thresholds = {}\n",
    "    default_threshold = ThresholdConfig(value=DEFAULT_THRESHOLD_VALUE)\n",
    "    for feature in default_thresholds.split(\",\"):\n",
    "        feature = feature.strip()\n",
    "        thresholds[feature] = default_threshold\n",
    "    for custom_threshold in custom_thresholds.split(\",\"):\n",
    "        pair = custom_threshold.split(\":\")\n",
    "        if len(pair) != 2:\n",
    "            print(f\"Invalid custom skew threshold: {custom_threshold}\")\n",
    "            return\n",
    "        feature, value = pair\n",
    "        thresholds[feature] = ThresholdConfig(value=float(value))\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "def get_deployed_model_ids(endpoint_id):\n",
    "    client_options = dict(api_endpoint=API_ENDPOINT)\n",
    "    client = EndpointServiceClient(client_options=client_options)\n",
    "    #parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "    #response = client.get_endpoint(name=f\"{parent}/endpoints/{endpoint_id}\")\n",
    "    response = client.get_endpoint(name=f\"{endpoint_id}\")\n",
    "    model_ids = []\n",
    "    for model in response.deployed_models:\n",
    "        model_ids.append(model.id)\n",
    "    return model_ids\n",
    "\n",
    "\n",
    "def set_objectives(model_ids, objective_template):\n",
    "    # Use the same objective config for all models.\n",
    "    objective_configs = []\n",
    "    for model_id in model_ids:\n",
    "        objective_config = copy.deepcopy(objective_template)\n",
    "        objective_config.deployed_model_id = model_id\n",
    "        objective_configs.append(objective_config)\n",
    "    return objective_configs\n",
    "\n",
    "\n",
    "def send_predict_request(endpoint, input):\n",
    "    client_options = {\"api_endpoint\": PREDICT_API_ENDPOINT}\n",
    "    client = PredictionServiceClient(client_options=client_options)\n",
    "    params = {}\n",
    "    params = json_format.ParseDict(params, Value())\n",
    "    request = PredictRequest(endpoint=endpoint, parameters=params)\n",
    "    inputs = [json_format.ParseDict(input, Value())]\n",
    "    request.instances.extend(inputs)\n",
    "    response = client.predict(request)\n",
    "    return response\n",
    "\n",
    "\n",
    "def list_monitoring_jobs():\n",
    "    client_options = dict(api_endpoint=API_ENDPOINT)\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/us-central1\"\n",
    "    client = JobServiceClient(client_options=client_options)\n",
    "    response = client.list_model_deployment_monitoring_jobs(parent=parent)\n",
    "    print(response)\n",
    "\n",
    "\n",
    "def pause_monitoring_job(job):\n",
    "    client_options = dict(api_endpoint=API_ENDPOINT)\n",
    "    client = JobServiceClient(client_options=client_options)\n",
    "    response = client.pause_model_deployment_monitoring_job(name=job)\n",
    "    print(response)\n",
    "\n",
    "\n",
    "def delete_monitoring_job(job):\n",
    "    client_options = dict(api_endpoint=API_ENDPOINT)\n",
    "    client = JobServiceClient(client_options=client_options)\n",
    "    response = client.delete_model_deployment_monitoring_job(name=job)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Monitoring job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Utility imports and constants\n",
    "import copy\n",
    "\n",
    "from google.cloud.aiplatform_v1beta1.services.endpoint_service import \\\n",
    "    EndpointServiceClient\n",
    "from google.cloud.aiplatform_v1beta1.services.job_service import \\\n",
    "    JobServiceClient\n",
    "from google.cloud.aiplatform_v1beta1.services.prediction_service import \\\n",
    "    PredictionServiceClient\n",
    "from google.cloud.aiplatform_v1beta1.types.io import BigQuerySource\n",
    "from google.cloud.aiplatform_v1beta1.types.io import GcsSource\n",
    "from google.cloud.aiplatform_v1beta1.types.model_deployment_monitoring_job import (\n",
    "    ModelDeploymentMonitoringJob, ModelDeploymentMonitoringObjectiveConfig,\n",
    "    ModelDeploymentMonitoringScheduleConfig)\n",
    "from google.cloud.aiplatform_v1beta1.types.model_monitoring import (\n",
    "    ModelMonitoringAlertConfig, ModelMonitoringObjectiveConfig,\n",
    "    SamplingStrategy, ThresholdConfig)\n",
    "from google.cloud.aiplatform_v1beta1.types.prediction_service import \\\n",
    "    PredictRequest\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.duration_pb2 import Duration\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "# This is the default value at which you would like the monitoring function to trigger an alert.\n",
    "# In other words, this value fine tunes the alerting sensitivity. This threshold can be customized\n",
    "# on a per feature basis but this is the global default setting.\n",
    "DEFAULT_THRESHOLD_VALUE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds specifying alerting criteria for training/serving skew and create config object.\n",
    "skew_thresholds = get_thresholds(SKEW_DEFAULT_THRESHOLDS, SKEW_CUSTOM_THRESHOLDS)\n",
    "skew_config = ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig(\n",
    "    skew_thresholds=skew_thresholds\n",
    ")\n",
    "\n",
    "# Set thresholds specifying alerting criteria for serving drift and create config object.\n",
    "drift_thresholds = get_thresholds(DRIFT_DEFAULT_THRESHOLDS, DRIFT_CUSTOM_THRESHOLDS)\n",
    "drift_config = ModelMonitoringObjectiveConfig.PredictionDriftDetectionConfig(\n",
    "    drift_thresholds=drift_thresholds\n",
    ")\n",
    "\n",
    "# Specify training dataset source location (used for schema generation). \n",
    "# BQ or Vertex Managed datasets can also be used as source\n",
    "training_dataset = ModelMonitoringObjectiveConfig.TrainingDataset(target_field=TARGET)\n",
    "training_dataset.data_format = 'csv'\n",
    "training_dataset.gcs_source = GcsSource(uris=DATASET_GCS_URI)\n",
    "\n",
    "\n",
    "# Aggregate the above settings into a ModelMonitoringObjectiveConfig object and use\n",
    "# that object to adjust the ModelDeploymentMonitoringObjectiveConfig object.\n",
    "objective_config = ModelMonitoringObjectiveConfig(\n",
    "    training_dataset=training_dataset,\n",
    "    training_prediction_skew_detection_config=skew_config,\n",
    "    prediction_drift_detection_config=drift_config,\n",
    ")\n",
    "objective_template = ModelDeploymentMonitoringObjectiveConfig(\n",
    "    objective_config=objective_config\n",
    ")\n",
    "\n",
    "# Find all deployed model ids on the created endpoint and set objectives for each.\n",
    "#model_ids = get_deployed_model_ids(ENDPOINT_ID)\n",
    "model_ids = get_deployed_model_ids(endpoint_id)\n",
    "objective_configs = set_objectives(model_ids, objective_template)\n",
    "\n",
    "# Create the monitoring job for all deployed models on this endpoint.\n",
    "monitoring_job = create_monitoring_job(objective_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Skewed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(IMPORT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To showcase drift, let's select only the records of people younger than 25\n",
    "skewed_data = data[data['Age']<=25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger training serving skew by sending skewed requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with same record multiple times\n",
    "#Can use this for skewing the data and triggering serving training skew \n",
    "for i in range(2000):\n",
    "    predict_item(INSTANCE, endpoint_id, None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to string types\n",
    "input_records[[\"Age\", \"Balance\", \"Day\",\"Duration\",\"Campaign\",\"PDays\",\"Previous\",\"Deposit\"]] = skewed_data[[\"Age\", \"Balance\", \"Day\",\"Duration\",\"Campaign\",\"PDays\",\"Previous\",\"Deposit\"]].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = input_records.Age.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to json format\n",
    "result = input_records.to_json(orient=\"records\")\n",
    "parsed_input = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send the records to prediction end-point\n",
    "for i in range(0,record_count):\n",
    "    resp = predict_item(parsed_input[i], endpoint_id, None, verbose=0)\n",
    "    print(resp['classes'][0])\n",
    "    print(resp['scores'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If a monitoring job needs to be deleted, use below calls\n",
    "#pause_monitoring_job(monitoring_job.name)\n",
    "#delete_monitoring_job(monitoring_job.name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m76"
  },
  "interpreter": {
   "hash": "aa023817591c8b00cad48ccb1a9b2c15f639a051eb314ccaceef6020d76e2839"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
